{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensor_tutorial.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Py3 research env",
      "language": "python",
      "name": "py3_research"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Civy2l4cos1t"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0PP8Tn6XWhO"
      },
      "source": [
        "_Credits: First two parts of this notebook are based on PyTorch official_ [tensor](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#sphx-glr-beginner-blitz-tensor-tutorial-py) _and_ [autograd](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html#sphx-glr-beginner-blitz-autograd-tutorial-py) _tutorials._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nEtOTFPos11"
      },
      "source": [
        "\n",
        "Once again, what is PyTorch?\n",
        "================\n",
        "\n",
        "It’s a Python-based scientific computing package targeted at two sets of\n",
        "audiences:\n",
        "\n",
        "-  A replacement for NumPy to use the power of GPUs\n",
        "-  a deep learning research platform that provides maximum flexibility\n",
        "   and speed\n",
        "\n",
        "Getting Started\n",
        "---------------\n",
        "\n",
        "#### Tensors\n",
        "\n",
        "Tensors are similar to NumPy’s ndarrays, with the addition being that\n",
        "Tensors can also be used on a GPU to accelerate computing.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCg57jzaos12"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2XO1pKzos17"
      },
      "source": [
        "Construct a 5x3 matrix, uninitialized:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4hzsf2Zos2A",
        "outputId": "12641cdc-e2d2-4f61-adaa-7b126557c6c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x = torch.empty(5, 3)\n",
        "print(x)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[9.1718e+04, 3.0861e-41, 3.3631e-44],\n",
            "        [0.0000e+00,        nan, 3.0861e-41],\n",
            "        [1.1578e+27, 1.1362e+30, 7.1547e+22],\n",
            "        [4.5828e+30, 1.2121e+04, 7.1846e+22],\n",
            "        [9.2198e-39, 7.0374e+22, 2.3834e+04]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1UXUAyfos2G"
      },
      "source": [
        "Construct a randomly initialized matrix:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pZuhVZdos2I",
        "outputId": "2def0f46-6df5-49f4-dd6a-85d4dc3283a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x = torch.rand(5, 3)\n",
        "print(x)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3636, 0.2049, 0.7367],\n",
            "        [0.1118, 0.3724, 0.4237],\n",
            "        [0.2196, 0.3743, 0.8934],\n",
            "        [0.3845, 0.4550, 0.0816],\n",
            "        [0.1904, 0.8753, 0.8730]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDuGrzjJos2O"
      },
      "source": [
        "Construct a matrix filled zeros and of dtype long:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7RuB4xhos2P",
        "outputId": "0246661c-335b-4967-fa78-e8fe55f66886",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x = torch.zeros(5, 3, dtype=torch.long)\n",
        "print(x)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dh6Esa3Fos2W"
      },
      "source": [
        "Construct a tensor directly from data:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnInKPIQos2X",
        "outputId": "a3d6c6bf-2002-4a55-d09c-9656eef459d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x = torch.tensor([5.5, 3])\n",
        "print(x)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5.5000, 3.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMJZ3uZQos2q"
      },
      "source": [
        "or create a tensor based on an existing tensor. These methods\n",
        "will reuse properties of the input tensor, e.g. dtype, unless\n",
        "new values are provided by user\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKfLS4Mios2r",
        "outputId": "4b479ad7-2d09-456a-f9a2-fc7878661619",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x = x.new_ones(5, 3, dtype=torch.double)      # new_* methods take in sizes\n",
        "print(x)\n",
        "\n",
        "x = torch.randn_like(x, dtype=torch.float)    # override dtype!\n",
        "print(x)                                      # result has the same size"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]], dtype=torch.float64)\n",
            "tensor([[-0.4216, -1.3187,  1.9725],\n",
            "        [ 0.0142, -0.7895, -0.9980],\n",
            "        [ 0.6697, -0.4934,  0.0366],\n",
            "        [-0.5853, -0.8145, -1.5701],\n",
            "        [ 0.3828,  0.3195, -1.1225]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yICWuQiPXWhY"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6M4dkilSXWhZ",
        "outputId": "6a4e200d-66ca-4606-e142-bab6f2ff2917",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "np.random.randint((2,5))\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HKFndN_XWha"
      },
      "source": [
        "a = np.random.randint((2,5))\n",
        "\n",
        "# Create a torch tensor from numpy tensor and cast it to float32 type\n",
        "a_t = torch.tensor(a, dtype=torch.float32)# YOUR CODE HERE\n",
        "assert a_t.dtype == torch.float32"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKXr5uY2XWhb",
        "outputId": "79096293-38a4-4167-89a1-d1c494f1fd24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "a_t"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 3.])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHcJcupjos2u"
      },
      "source": [
        "Get its size:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glNo_10Kos2v",
        "outputId": "122bef55-b6dc-4828-b8be-e132cc10b1d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(x.size())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PtBBxVIXWhc",
        "outputId": "23d9fef6-b417-436b-d27d-65a19cd8e513",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x.shape[:2]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_scE1Qvwos21"
      },
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>``torch.Size`` is in fact a tuple, so it supports all tuple operations.</p></div>\n",
        "\n",
        "#### Operations\n",
        "\n",
        "There are multiple syntaxes for operations. In the following\n",
        "example, we will take a look at the addition operation.\n",
        "\n",
        "Addition: syntax 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luQAJTT9os22",
        "outputId": "f9f889e7-3e03-4b0f-b974-739b3761c75d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y = torch.rand(5, 3)\n",
        "print(x + y)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0353, -1.0633,  2.0648],\n",
            "        [ 0.9004,  0.0924, -0.0863],\n",
            "        [ 0.7228,  0.0775,  0.1363],\n",
            "        [-0.3208, -0.5059, -1.2328],\n",
            "        [ 1.0743,  1.0022, -0.7016]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8s8E-Q2os26"
      },
      "source": [
        "Addition: syntax 2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLwb3hgyos28",
        "outputId": "3741ae7d-aed4-4d38-8fff-7f131aff67af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(torch.add(x, y))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0353, -1.0633,  2.0648],\n",
            "        [ 0.9004,  0.0924, -0.0863],\n",
            "        [ 0.7228,  0.0775,  0.1363],\n",
            "        [-0.3208, -0.5059, -1.2328],\n",
            "        [ 1.0743,  1.0022, -0.7016]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dItCJmIos2_"
      },
      "source": [
        "Addition: providing an output tensor as argument\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTXFN-TTos3B",
        "outputId": "f4491245-1d31-4b1c-daac-47d25d959a33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "result = torch.empty(5, 3)\n",
        "torch.add(x, y, out=result)\n",
        "print(result)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0353, -1.0633,  2.0648],\n",
            "        [ 0.9004,  0.0924, -0.0863],\n",
            "        [ 0.7228,  0.0775,  0.1363],\n",
            "        [-0.3208, -0.5059, -1.2328],\n",
            "        [ 1.0743,  1.0022, -0.7016]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmLxccujos3F"
      },
      "source": [
        "Addition: in-place\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udSpL0x0os3H",
        "outputId": "57e8ad07-87da-468c-f03c-234512c71565",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# adds x to y\n",
        "y.add_(x)\n",
        "print(y)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0353, -1.0633,  2.0648],\n",
            "        [ 0.9004,  0.0924, -0.0863],\n",
            "        [ 0.7228,  0.0775,  0.1363],\n",
            "        [-0.3208, -0.5059, -1.2328],\n",
            "        [ 1.0743,  1.0022, -0.7016]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqQU0LO0os3M"
      },
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>Any operation that mutates a tensor in-place is post-fixed with an ``_``.\n",
        "    For example: ``x.copy_(y)``, ``x.t_()``, will change ``x``.</p></div>\n",
        "\n",
        "You can use standard NumPy-like indexing with all bells and whistles!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcuoNbqOos3Q",
        "outputId": "0ace3267-0e70-4adc-b836-841506e0edc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(x[:, 1])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-1.3187, -0.7895, -0.4934, -0.8145,  0.3195])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyKhJ4E8os3U"
      },
      "source": [
        "Resizing: If you want to resize/reshape tensor, you can use ``torch.view``:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmCUrv3qos3V",
        "outputId": "dd49b38a-9ae6-4223-a536-d1ce806882ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x = torch.randn(4, 4)\n",
        "y = x.view(16)\n",
        "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
        "print(x.size(), y.size(), z.size())"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Srv3YKMMos3Y"
      },
      "source": [
        "If you have a one element tensor, use ``.item()`` to get the value as a\n",
        "Python number\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s13XZt8Cos3Z",
        "outputId": "973bb464-0ba1-4c72-ab16-c03932991e30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x = torch.randn(1)\n",
        "print(x)\n",
        "print(x.item())"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.9808])\n",
            "-0.9808289408683777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orMsQvQAos3c"
      },
      "source": [
        "**Read later:**\n",
        "\n",
        "\n",
        "  100+ Tensor operations, including transposing, indexing, slicing,\n",
        "  mathematical operations, linear algebra, random numbers, etc.,\n",
        "  are described\n",
        "  `here <http://pytorch.org/docs/torch>`_.\n",
        "\n",
        "NumPy Bridge\n",
        "------------\n",
        "\n",
        "Converting a Torch Tensor to a NumPy array and vice versa is a breeze.\n",
        "\n",
        "The Torch Tensor and NumPy array will share their underlying memory\n",
        "locations, and changing one will change the other.\n",
        "\n",
        "#### Converting a Torch Tensor to a NumPy Array\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOdXxb_Vos3d",
        "outputId": "7443251d-fa0e-4f9c-e728-229258b4837a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "a = torch.ones(5)\n",
        "print(a)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68cPoOiIos3i",
        "outputId": "13b53699-05db-46ed-a82a-3e3340889ee0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "b = a.numpy()\n",
        "print(b)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 1. 1. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9q-JAGdos3n"
      },
      "source": [
        "See how the numpy array changed in value.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-AYXf1Los3p",
        "outputId": "39797a2e-ea05-4786-eea3-e93f060dc24a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "a.add_(1)\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2., 2., 2., 2., 2.])\n",
            "[2. 2. 2. 2. 2.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QtC7o0zos3s"
      },
      "source": [
        "#### Converting NumPy Array to Torch Tensor\n",
        "\n",
        "See how changing the np array changed the Torch Tensor automatically\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxF1_zXDos3t",
        "outputId": "b63e8367-75ca-41b0-c5a3-74dcd3a9cec1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "a = np.ones(5)\n",
        "b = torch.from_numpy(a)\n",
        "np.add(a, 1, out=a)\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2. 2. 2. 2. 2.]\n",
            "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-w5pWYnaos3w"
      },
      "source": [
        "All the Tensors on the CPU except a CharTensor support converting to\n",
        "NumPy and back.\n",
        "\n",
        "CUDA Tensors\n",
        "------------\n",
        "\n",
        "Tensors can be moved onto any device using the ``.to`` method.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHW5QuDSos3x"
      },
      "source": [
        "# let us run this cell only if CUDA is available\n",
        "# We will use ``torch.device`` objects to move tensors in and out of GPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")          # a CUDA device object\n",
        "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
        "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
        "    z = x + y\n",
        "    print(z)\n",
        "    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgt0RPz3XWhm",
        "outputId": "8a1cc2c5-0d13-4243-96d0-dccfba913012",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "z.device"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-tAuF7VXWhn",
        "outputId": "711abce5-4fe1-47fd-9f98-8660b40fb35d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "z.shape"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1tfEAwhXWho"
      },
      "source": [
        "a = torch.ones((2, 8))"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ua2epYNyXWhp",
        "outputId": "dffa9af7-9a56-4b6e-d222-9a18b81c8eab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "z.to(\"cpu\") + a"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.8215, -0.7764,  0.4054,  0.4070,  0.0400,  1.1470,  2.6411,  0.7450],\n",
              "        [ 1.7680,  2.5602,  1.9960,  1.8257,  1.9134,  1.0848, -0.2604,  2.0185]])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iqh6fwauXWhp",
        "outputId": "9a3dee1e-0250-47c6-b305-1c7f49d94bb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x.device"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3-Cuo4cXWhq",
        "outputId": "785a01f9-b850-4bc5-f845-0d5fd81cba42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIvSd_XnXWhq"
      },
      "source": [
        "\n",
        "Autograd: Automatic Differentiation\n",
        "===================================\n",
        "\n",
        "Central to all neural networks in PyTorch is the ``autograd`` package.\n",
        "Let’s first briefly visit this, and we will then go to training our\n",
        "first neural network.\n",
        "\n",
        "\n",
        "The ``autograd`` package provides automatic differentiation for all operations\n",
        "on Tensors. It is a define-by-run framework, which means that your backprop is\n",
        "defined by how your code is run, and that every single iteration can be\n",
        "different.\n",
        "\n",
        "Let us see this in more simple terms with some examples.\n",
        "\n",
        "Tensor\n",
        "--------\n",
        "\n",
        "``torch.Tensor`` is the central class of the package. If you set its attribute\n",
        "``.requires_grad`` as ``True``, it starts to track all operations on it. When\n",
        "you finish your computation you can call ``.backward()`` and have all the\n",
        "gradients computed automatically. The gradient for this tensor will be\n",
        "accumulated into ``.grad`` attribute.\n",
        "\n",
        "To stop a tensor from tracking history, you can call ``.detach()`` to detach\n",
        "it from the computation history, and to prevent future computation from being\n",
        "tracked.\n",
        "\n",
        "To prevent tracking history (and using memory), you can also wrap the code block\n",
        "in ``with torch.no_grad():``. This can be particularly helpful when evaluating a\n",
        "model because the model may have trainable parameters with `requires_grad=True`,\n",
        "but for which we don't need the gradients.\n",
        "\n",
        "There’s one more class which is very important for autograd\n",
        "implementation - a ``Function``.\n",
        "\n",
        "``Tensor`` and ``Function`` are interconnected and build up an acyclic\n",
        "graph, that encodes a complete history of computation. Each tensor has\n",
        "a ``.grad_fn`` attribute that references a ``Function`` that has created\n",
        "the ``Tensor`` (except for Tensors created by the user - their\n",
        "``grad_fn is None``).\n",
        "\n",
        "If you want to compute the derivatives, you can call ``.backward()`` on\n",
        "a ``Tensor``. If ``Tensor`` is a scalar (i.e. it holds a one element\n",
        "data), you don’t need to specify any arguments to ``backward()``,\n",
        "however if it has more elements, you need to specify a ``gradient``\n",
        "argument that is a tensor of matching shape.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6xhGBBjXWhq"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4j0sbT-nXWhr"
      },
      "source": [
        "Create a tensor and set requires_grad=True to track computation with it\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w75gttBRXWhr",
        "outputId": "b462a145-87fa-4b05-f285-9fd8bc719b9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x = torch.ones(2, 2, requires_grad=True)\n",
        "print(x)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geOhzy_5XWhr"
      },
      "source": [
        "Do an operation of tensor:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyM8FReWXWhr",
        "outputId": "16ead799-8e4e-41ca-de73-32d07f65541f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y = x + 2\n",
        "print(y)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[3., 3.],\n",
            "        [3., 3.]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQX5nuixXWhr"
      },
      "source": [
        "``y`` was created as a result of an operation, so it has a ``grad_fn``.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82-wk49sXWhs",
        "outputId": "361f583e-ab88-456a-ae42-ff7d4193ea02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(y.grad_fn)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<AddBackward0 object at 0x7f67dbf58790>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcBd8nYJXWhs"
      },
      "source": [
        "Do more operations on y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMyhn2yaXWhs",
        "outputId": "451422f2-46ea-4263-923f-9e86a69243db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "z = y * y * 3\n",
        "out = z.mean()\n",
        "\n",
        "print(z, out)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[27., 27.],\n",
            "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GP5Kfl-gXWhs"
      },
      "source": [
        "``.requires_grad_( ... )`` changes an existing Tensor's ``requires_grad``\n",
        "flag in-place. The input flag defaults to ``False`` if not given.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWq2dTkIXWhs",
        "outputId": "0ce6dc31-adf1-4120-8162-bb89d42ee7b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "a = torch.randn(2, 2)\n",
        "a = ((a * 3) / (a - 1))\n",
        "print(a.requires_grad)\n",
        "a.requires_grad_(True)\n",
        "print(a.requires_grad)\n",
        "b = (a * a).sum()\n",
        "print(b.grad_fn)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "True\n",
            "<SumBackward0 object at 0x7f67dbf99e10>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDS2F_x8XWht"
      },
      "source": [
        "Gradients\n",
        "---------\n",
        "Let's backprop now\n",
        "Because ``out`` contains a single scalar, ``out.backward()`` is\n",
        "equivalent to ``out.backward(torch.tensor(1))``.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_xPZxYHXWht"
      },
      "source": [
        "out.backward()"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMPZY_i5XWht"
      },
      "source": [
        "print gradients d(out)/dx\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxZQuJ2dXWhu",
        "outputId": "a22523b6-0b30-4768-8d62-fc50c0ca416b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(x.grad)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[4.5000, 4.5000],\n",
            "        [4.5000, 4.5000]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qHhOM5cXWhu"
      },
      "source": [
        "You should have got a matrix of ``4.5``. Let’s call the ``out``\n",
        "*Tensor* “$o$”.\n",
        "We have that \n",
        "$$o = \\frac{1}{4}\\sum_i z_i,$$\n",
        "\n",
        "$$z_i = 3(x_i+2)^2$$ and $$z_i\\bigr\\rvert_{x_i=1} = 27$$\n",
        "\n",
        "Therefore,\n",
        "\n",
        "$$\\frac{\\partial o}{\\partial x_i} = \\frac{3}{2}(x_i+2),$$ hence\n",
        "$$\\frac{\\partial o}{\\partial x_i}\\bigr\\rvert_{x_i=1} = \\frac{9}{2} = 4.5$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgXelTEDXWhu"
      },
      "source": [
        "You can do many crazy things with autograd!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVVlx9GTXWhv",
        "outputId": "f74d59f4-f0ac-431a-a045-6299d7dfcd20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x = torch.randn(3, requires_grad=True)\n",
        "\n",
        "y = x * 2\n",
        "while y.data.norm() < 1000:\n",
        "    y = y * 2\n",
        "\n",
        "print(y)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-994.7377,  -23.9637,  246.1274], grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrOxqlI1XWhv",
        "outputId": "50396c4b-6fcb-4f9b-8dd7-074df2c7b966",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "gradients = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)\n",
        "y.backward(gradients)\n",
        "\n",
        "print(x.grad)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5.1200e+01, 5.1200e+02, 5.1200e-02])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ASkHPvZXWhv"
      },
      "source": [
        "You can also stop autograd from tracking history on Tensors\n",
        "with ``.requires_grad=True`` by wrapping the code block in\n",
        "``with torch.no_grad()``:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VGspS4BXWhw",
        "outputId": "54491516-4979-4cbc-ec1f-f991f9ef3e27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(x.requires_grad)\n",
        "print((x ** 2).requires_grad)\n",
        "\n",
        "with torch.no_grad():\n",
        "    print((x ** 2).requires_grad)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYorAGa8XWhx"
      },
      "source": [
        "**Read Later:**\n",
        "\n",
        "Documentation of ``autograd`` and ``Function`` is at\n",
        "http://pytorch.org/docs/autograd\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7OV52kcXWhx"
      },
      "source": [
        "def plot_train_process(train_loss, val_loss, train_accuracy, val_accuracy, title_suffix=''):\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "    axes[0].set_title(' '.join(['Loss', title_suffix]))\n",
        "    axes[0].plot(train_loss, label='train')\n",
        "    axes[0].plot(val_loss, label='validation')\n",
        "    axes[0].legend()\n",
        "\n",
        "    axes[1].set_title(' '.join(['Validation accuracy', title_suffix]))\n",
        "    axes[1].plot(train_accuracy, label='train')\n",
        "    axes[1].plot(val_accuracy, label='validation')\n",
        "    axes[1].legend()\n",
        "    plt.show()"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xEzc7mRXWhy"
      },
      "source": [
        "### Dealing with the simple task\n",
        "Now we will tackle the car classification problem with new techniques: neural networks. Let's get started"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6ZoLD_CXWhy"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isRkvGQaXWhy"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZSWixBsXWhz",
        "outputId": "d44a58d6-3077-469b-d263-4ac520b41304",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "try:\n",
        "    dataset = pd.read_csv('../datasets/car_dataset/car_data.csv', delimiter=',', header=None).values\n",
        "except FileNotFoundError:\n",
        "    !wget https://raw.githubusercontent.com/neychev/made_nlp_course/master/datasets/car_dataset/car_data.csv -nc\n",
        "    dataset = pd.read_csv('car_data.csv', delimiter=',', header=None).values"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-02 18:19:51--  https://raw.githubusercontent.com/neychev/made_nlp_course/master/datasets/car_dataset/car_data.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 58374 (57K) [text/plain]\n",
            "Saving to: ‘car_data.csv’\n",
            "\n",
            "car_data.csv        100%[===================>]  57.01K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2021-10-02 18:19:52 (4.16 MB/s) - ‘car_data.csv’ saved [58374/58374]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yWuVUqCXWhz",
        "outputId": "1bc56b34-a248-4b81-ed3d-11f50bc7417b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data = dataset[:, :-1].astype(int)\n",
        "target = dataset[:, -1]\n",
        "\n",
        "print(data.shape, target.shape)\n",
        "\n",
        "X_train, X_test, y_train_raw, y_test_raw = train_test_split(data, target, test_size=0.15)\n",
        "print(X_train.shape, y_train_raw.shape, X_test.shape, y_test_raw.shape)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(846, 19) (846,)\n",
            "(719, 19) (719,) (127, 19) (127,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lTsaHtpXWhz"
      },
      "source": [
        "Now we need to map all the class labels to numbers with some `dict`. PyTorch does not like non-numeric labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ILh2kOxP-E0",
        "outputId": "168dd423-e58e-4d86-a80b-09726a5a77b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "labels = dict(enumerate(set(target)))\n",
        "labels = dict(zip(labels.values(), labels.keys()))\n",
        "labels"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bus': 1, 'opel': 0, 'saab': 2, 'van': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pq_LzEYiXWhz"
      },
      "source": [
        "mapper = lambda x: labels[x] # YOUR CODE HERE\n",
        "y_train = np.array([mapper(y) for y in y_train_raw])\n",
        "y_test = np.array([mapper(y) for y in y_test_raw])"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9h5D2AIIXWh0"
      },
      "source": [
        "And let's preprocess the feature matrices as well"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHguLQOWXWh0"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler() # YOUR CODE HERE\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train) # YOUR CODE HERE\n",
        "X_test_scaled = scaler.fit_transform(X_test) # YOUR CODE HERE\n"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUpzCxfKXWh0",
        "outputId": "61c02d68-93ba-4f2e-f40b-3364e883fd52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_train_scaled"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.45572148, -0.91820031, -0.7815652 , ..., -1.08809757,\n",
              "        -1.43021406, -1.4166269 ],\n",
              "       [-1.17597706,  1.13694753,  1.48630315, ...,  0.58930842,\n",
              "         0.02519012,  0.59288528],\n",
              "       [ 0.93033386, -0.55552716,  0.02838778, ...,  0.36565429,\n",
              "        -0.94507933, -0.34488707],\n",
              "       ...,\n",
              "       [-0.37788269, -0.79730926, -0.6195746 , ..., -0.52896224,\n",
              "         0.1869017 , -0.21091959],\n",
              "       [-0.07345494, -0.67641821, -1.42952758, ...,  2.49036855,\n",
              "         0.833748  ,  0.86082024],\n",
              "       [-1.36110204, -1.4017645 ,  0.02838778, ..., -1.31175171,\n",
              "        -1.26850249, -1.4166269 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSfxk-H3XWh1"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "import torchsummary"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTbibHD5XWh1"
      },
      "source": [
        "model = nn.Sequential()\n",
        "model.add_module('l1', nn.Linear(19, 4))"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLk9RICxXWh2",
        "outputId": "ea4a8850-1cca-4fa8-edce-23a18893047f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "torchsummary.summary(model, (19,))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                    [-1, 4]              80\n",
            "================================================================\n",
            "Total params: 80\n",
            "Trainable params: 80\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.00\n",
            "Estimated Total Size (MB): 0.00\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3DPp1MdXWh2",
        "outputId": "9a19d9d0-0f2f-476c-94fb-4c7cae665fc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(719, 19)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqHXCu9CXWh2"
      },
      "source": [
        "opt = torch.optim.AdamW(model.parameters(), lr=3e-3)"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7v2T87eXWh3"
      },
      "source": [
        "And here comes the loss function as well. `nn.CrossEntropyLoss` combines both log-softmax and `NLLLoss`.\n",
        "__Be careful with it! Criterion `nn.CrossEntropyLoss` with still work with log-softmax output, but it won't allow you to converge to the optimum.__ Next comes small demonstration:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5WDhdPBXWh3"
      },
      "source": [
        "x = torch.randn((1, 10))"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-QJoRQhXWh3",
        "outputId": "7eb1033b-d21c-4b08-bc41-2df2c672efa7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "x_new = x\n",
        "for n_sequential_softmax_transforms in range(1, 5):\n",
        "    x_new = F.softmax(x_new, dim=1)\n",
        "    \n",
        "    fig = plt.figure()\n",
        "    plt.bar(range(10), x_new.numpy().squeeze())\n",
        "    plt.title('N sequential softmax transforms: {}'.format(n_sequential_softmax_transforms))\n",
        "    plt.show()"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDS0phowXWh3"
      },
      "source": [
        "As you can see, the _entropy_ of the labels distribution increases (so it becomes closer to uniform) if you use several `softmax` transformations in a row. But it won't affect the accuracy at first sight, because softmax preserves the maximum value position."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_oR1CUrXWh4"
      },
      "source": [
        "# loss_function = nn.NLLLoss()\n",
        "loss_function = nn.CrossEntropyLoss()"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGS_RI4KXWh5"
      },
      "source": [
        "X_train_torch = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
        "X_test_torch = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
        "\n",
        "y_train_torch = torch.tensor(y_train, dtype=torch.long)\n",
        "y_test_torch = torch.tensor(y_test, dtype=torch.long)"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7twb5QmXWh6",
        "outputId": "d212937f-10b1-435f-94df-224d635ed588",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# example loss\n",
        "loss_function(model(X_train_torch[:3]), y_train_torch[:3])"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.1846, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sp6Tc9IzXWh6",
        "outputId": "70499eac-7808-4308-9cfb-027f844286f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install scikit-plot"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-plot\n",
            "  Downloading scikit_plot-0.3.7-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (1.4.1)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (3.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.10 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (1.0.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.19.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.3.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=1.4.0->scikit-plot) (1.15.0)\n",
            "Installing collected packages: scikit-plot\n",
            "Successfully installed scikit-plot-0.3.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5E_QxP_XWh6"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import scikitplot"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uK-pIaxSXWh7"
      },
      "source": [
        "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOuiv43zXWh7"
      },
      "source": [
        "# To reduce learning rate on plateau of the loss functions\n",
        "lr_scheduler = ReduceLROnPlateau(opt, patience=5)"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWvh0-psXWh7",
        "outputId": "3ce76a01-fd52-4986-fc48-33dff252f0da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "opt"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AdamW (\n",
              "Parameter Group 0\n",
              "    amsgrad: False\n",
              "    betas: (0.9, 0.999)\n",
              "    eps: 1e-08\n",
              "    lr: 0.003\n",
              "    weight_decay: 0.01\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkpQOJZvXWh7"
      },
      "source": [
        "from IPython import display"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "bZpmvm9KXWh8",
        "outputId": "9d78e47f-0a5e-40b1-b661-d1a2dee0b872",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "train_loss_history = []\n",
        "train_acc_history = []\n",
        "val_loss_history = []\n",
        "val_acc_history = []\n",
        "\n",
        "local_train_loss_history = []\n",
        "local_train_acc_history = []\n",
        "for i in range(5000):\n",
        "    \n",
        "    # sample 256 random observations\n",
        "    ix = np.random.randint(0, len(X_train), 256)\n",
        "    x_batch = X_train_torch[ix]\n",
        "    y_batch = y_train_torch[ix]\n",
        "    \n",
        "    # predict log-probabilities or logits\n",
        "    ### YOUR CODE\n",
        "    \n",
        "    # compute loss, just like before\n",
        "    loss = ### YOUR CODE\n",
        "\n",
        "    \n",
        "    # compute gradients\n",
        "    ### YOUR CODE\n",
        "    \n",
        "    # Adam step\n",
        "    ### YOUR CODE\n",
        "    \n",
        "    # clear gradients\n",
        "    ### YOUR CODE\n",
        "    \n",
        "    local_train_loss_history.append(loss.data.numpy())\n",
        "    local_train_acc_history.append(\n",
        "        accuracy_score(\n",
        "            y_batch.detach().numpy(),\n",
        "            y_predicted.detach().numpy().argmax(axis=1)\n",
        "        )\n",
        "    )\n",
        "    \n",
        "    if i % 200 == 0:\n",
        "        train_loss_history.append(np.mean(local_train_loss_history))\n",
        "        train_acc_history.append(np.mean(local_train_acc_history))\n",
        "        local_train_loss_history, local_train_acc_history = [], []\n",
        "\n",
        "        predictions_val = model(X_test_torch)\n",
        "        val_loss_history.append(loss_function(predictions_val, y_test_torch).detach().item())\n",
        "        \n",
        "        acc_score_val = accuracy_score(y_test, predictions_val.detach().numpy().argmax(axis=1))\n",
        "        val_acc_history.append(acc_score_val)\n",
        "        lr_scheduler.step(train_loss_history[-1])\n",
        "        \n",
        "        display.clear_output()\n",
        "        plot_train_process(train_loss_history, val_loss_history, train_acc_history, val_acc_history)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-93-38f269fd49e1>\"\u001b[0;36m, line \u001b[0;32m19\u001b[0m\n\u001b[0;31m    loss = ### YOUR CODE\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiisWeOoXWh8"
      },
      "source": [
        "Now we get the predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idY1iqixXWh8"
      },
      "source": [
        "y_predicted_train = model(torch.from_numpy(\n",
        "    X_train_scaled\n",
        ").type(torch.float32)).detach().numpy()\n",
        "\n",
        "\n",
        "y_predicted_test = model(torch.from_numpy(\n",
        "    X_test_scaled\n",
        ").type(torch.float32)).detach().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEI5uoEZXWh8"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import scikitplot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKIx1-AkXWh9"
      },
      "source": [
        "print('Accuracy train: {}\\nAccuracy  test: {}\\nf1 train: {}\\nf1 test: {}'.format(\n",
        "    accuracy_score(y_train, np.argmax(y_predicted_train, axis=1)),\n",
        "    accuracy_score(y_test, np.argmax(y_predicted_test, axis=1)),\n",
        "    f1_score(y_train, np.argmax(y_predicted_train, axis=1), average='macro'),\n",
        "    f1_score(y_test, np.argmax(y_predicted_test, axis=1), average='macro')\n",
        "))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqUEucq4XWh9"
      },
      "source": [
        "print('Accuracy train: {}\\nAccuracy  test: {}\\nf1 train: {}\\nf1 test: {}'.format(\n",
        "    accuracy_score(y_train, np.argmax(y_predicted_train, axis=1)),\n",
        "    accuracy_score(y_test, np.argmax(y_predicted_test, axis=1)),\n",
        "    f1_score(y_train, np.argmax(y_predicted_train, axis=1), average='weighted'),\n",
        "    f1_score(y_test, np.argmax(y_predicted_test, axis=1), average='weighted')\n",
        "))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jfj5wFpDXWh9"
      },
      "source": [
        "scikitplot.metrics.plot_roc(y_test, y_predicted_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXt_D4DwXWh9"
      },
      "source": [
        "__Not that good, yeah? Let's get back and make it really work__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ca6ojifaXWh9"
      },
      "source": [
        "### And now let's do in with texts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsO-4rsJXWh-"
      },
      "source": [
        "try:\n",
        "    data = pd.read_csv('../datasets/comments_small_dataset/comments.tsv', sep='\\t')\n",
        "except FileNotFoundError:\n",
        "    ! wget https://raw.githubusercontent.com/neychev/made_nlp_course/master/datasets/comments_small_dataset/comments.tsv -nc\n",
        "    data = pd.read_csv(\"comments.tsv\", sep='\\t')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qU0EblSkXWh-"
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(\"comments.tsv\", sep='\\t')\n",
        "\n",
        "texts = data['comment_text'].values\n",
        "target = data['should_ban'].values\n",
        "data[50::200]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOQWSUC3XWh-"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "texts_train, texts_test, y_train, y_test = train_test_split(texts, target, test_size=0.5, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B78QvoM8XWh-"
      },
      "source": [
        "from nltk.tokenize import TweetTokenizer\n",
        "tokenizer = TweetTokenizer()\n",
        "preprocess = lambda text: ' '.join(tokenizer.tokenize(text.lower()))\n",
        "\n",
        "text = 'How to be a grown-up at work: replace \"I don\\'t want to do that\" with \"Ok, great!\".'\n",
        "print(\"before:\", text,)\n",
        "print(\"after:\", preprocess(text),)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myxVmk_bXWh_"
      },
      "source": [
        "\n",
        "# task: preprocess each comment in train and test\n",
        "\n",
        "texts_train =  ### YOUR CODE HERE\n",
        "texts_test = ### YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxQpuyy2XWh_"
      },
      "source": [
        "assert texts_train[5] ==  'who cares anymore . they attack with impunity .'\n",
        "assert texts_test[89] == 'hey todds ! quick q ? why are you so gay'\n",
        "assert len(texts_test) == len(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUnaQSQmXWh_"
      },
      "source": [
        "# task: find up to k most frequent tokens in texts_train,\n",
        "# sort them by number of occurences (highest first)\n",
        "\n",
        "k = min(10000, len(set(' '.join(texts_train).split())))\n",
        "bow_vocabulary = ### YOUR CODE HERE\n",
        "\n",
        "print('example features:', sorted(bow_vocabulary)[::100])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJh5zapVXWiA"
      },
      "source": [
        "def text_to_bow(text):\n",
        "    \"\"\" convert text string to an array of token counts. Use bow_vocabulary. \"\"\"\n",
        "    #<YOUR CODE>\n",
        "\n",
        "    return np.array(<...>, 'float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siYtLha6XWiA"
      },
      "source": [
        "X_train_bow = np.stack(list(map(text_to_bow, texts_train)))\n",
        "X_test_bow = np.stack(list(map(text_to_bow, texts_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Io5R30QCXWiB"
      },
      "source": [
        "# Small check that everything is done properly\n",
        "k_max = len(set(' '.join(texts_train).split()))\n",
        "assert X_train_bow.shape == (len(texts_train), min(k, k_max))\n",
        "assert X_test_bow.shape == (len(texts_test), min(k, k_max))\n",
        "assert np.all(X_train_bow[5:10].sum(-1) == np.array([len(s.split()) for s in  texts_train[5:10]]))\n",
        "assert len(bow_vocabulary) <= min(k, k_max)\n",
        "assert X_train_bow[6, bow_vocabulary.index('.')] == texts_train[6].split().count('.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFw8OlutXWiC"
      },
      "source": [
        "Let's solve it using `sklearn` logistic regression model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixA4tDKkXWiC"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "bow_model = LogisticRegression().fit(X_train_bow, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyEB3W7zXWiC"
      },
      "source": [
        "X_train_bow.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONS-CirqXWiD"
      },
      "source": [
        "model.score(X_train_bow, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDCRSkR8XWiD"
      },
      "source": [
        "model.score(X_test_bow, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aptnDsI4XWiE"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "\n",
        "for name, X, y, model in [\n",
        "    ('train', X_train_bow, y_train, bow_model),\n",
        "    ('test ', X_test_bow, y_test, bow_model)\n",
        "]:\n",
        "    proba = model.predict_proba(X)[:, 1]\n",
        "    auc = roc_auc_score(y, proba)\n",
        "    plt.plot(*roc_curve(y, proba)[:2], label='%s AUC=%.4f' % (name, auc))\n",
        "\n",
        "plt.plot([0, 1], [0, 1], '--', color='black',)\n",
        "plt.legend(fontsize='large')\n",
        "plt.grid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9wFbviUXWiE"
      },
      "source": [
        "And now let's achieve similar results using PyTorch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFe6SG3lXWiF"
      },
      "source": [
        "linear_model = ### YOUR CODE HERE\n",
        "opt = ### YOUR CODE HERE\n",
        "loss_func = ### YOUR CODE HERE\n",
        "\n",
        "X_train_bow_torch = torch.from_numpy(X_train_bow)\n",
        "y_train_torch = torch.from_numpy(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDfAG9ihXWiF"
      },
      "source": [
        "# Simple training loop. No need in batch generation in here\n",
        "for _ in range(100):\n",
        "    ### YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NJrZJjbXWiF"
      },
      "source": [
        "y_pred_train = linear_model(X_train_bow_torch).argmax(dim=1).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNnxRhzfXWiG"
      },
      "source": [
        "y_pred_test = linear_model(torch.from_numpy(X_test_bow)).argmax(dim=1).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTtexSKkXWiH"
      },
      "source": [
        "np.mean(y_pred_train == y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVwVIPQYXWiI"
      },
      "source": [
        "np.mean(y_pred_test == y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYkqiVhfXWiL"
      },
      "source": [
        "### Extra stuff: NotMNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYvSGSx8XWiL"
      },
      "source": [
        "! wget https://raw.githubusercontent.com/neychev/made_nlp_course/master/week01_Intro/notmnist.py -nc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehGFP59KXWiM"
      },
      "source": [
        "from notmnist import load_notmnist\n",
        "X_train, y_train, X_test, y_test = load_notmnist()\n",
        "X_train, X_test = X_train.reshape([-1, 784]), X_test.reshape([-1, 784])\n",
        "\n",
        "print(\"Train size = %i, test_size = %i\"%(len(X_train),len(X_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nS2Pk2AGXWiM"
      },
      "source": [
        "for i in [0,1]:\n",
        "    plt.subplot(1, 2, i + 1)\n",
        "    plt.imshow(X_train[i].reshape([28,28]))\n",
        "    plt.title(str(y_train[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zxrzp7EXWiM"
      },
      "source": [
        "# Your turn: create a multiclass classifier in here for notMNIST dataset."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-40wQrw3XWiM"
      },
      "source": [
        "# create a network that stacks layers on top of each other\n",
        "model = nn.Sequential()\n",
        "\n",
        "# add first \"dense\" layer with 784 input units and 1 output unit. \n",
        "model.add_module('l1', # YOUR CODE HERE)\n",
        "model.add_module('a1', # YOUR CODE HERE)\n",
        "..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdNgZ0HpXWiN"
      },
      "source": [
        "Take a look at the model structure:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJSMOQa3XWiN"
      },
      "source": [
        "torchsummary.summary(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtSTuNZVXWiN"
      },
      "source": [
        "Let's check that everything works correctly:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvhKB2J5XWiO"
      },
      "source": [
        "# create dummy data with 3 samples and 784 features\n",
        "x = torch.tensor(X_train[:3], dtype=torch.float32)\n",
        "y = torch.tensor(y_train[:3], dtype=torch.float32)\n",
        "\n",
        "# compute outputs given inputs, both are variables\n",
        "y_predicted = model(x)[:, 0]\n",
        "\n",
        "y_predicted # display what we've got"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFdneDfqXWiO"
      },
      "source": [
        "Let's call the loss function from `torch.nn`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAehJgkNXWiO"
      },
      "source": [
        "loss_function = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHPSJuBnXWiO"
      },
      "source": [
        "Define some optimizer for your model parameters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YO_NdyHFXWiP"
      },
      "source": [
        "opt = # YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3QwkFXDXWiP"
      },
      "source": [
        "Compute the loss for some batch of objects:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWnBLKGoXWiP"
      },
      "source": [
        "loss = # YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9WSJyPdXWiP"
      },
      "source": [
        "Do a backward pass and optimizator step:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvoRZ27mXWiP"
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqOpiol1XWiP"
      },
      "source": [
        "Finally, implement the optimization pipeline and monitor the model quality during the optimization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEyRTt6HXWiP"
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
